# config file for robotito
max_level:10
max_nodes:50000
max_list_size:10000
mode:freq

#-- borrowed from Nutch crawler
rule:-^(?:file|ftp|mailto):

# skip URLs longer than 2048 characters, see also db.max.outlink.length
rule:-^.{2049,}

# skip URLs containing certain characters as probable queries, etc.
rule:-[?*!@=]

# skip URLs with slash-delimited segment that repeats 3+ times, to break loops
rule:-.*(/[^/]+)/[^/]+\1/[^/]+\1/

rule:-(?i)\.(?:gif|jpg|png|ico|css|sit|eps|wmf|zip|ppt|mpg|xls|gz|rpm|tgz|mov|exe|jpeg|bmp|js)$

rule:+exlibris\.usal\.es

cyberfile:exlibrisK.csv
cyberrule:+.*
cyberrule:-(?i)\.(?:gif|jpg|png|ico|css|sit|eps|wmf|zip|ppt|mpg|xls|gz|rpm|tgz|mov|exe|jpeg|bmp|js)$


